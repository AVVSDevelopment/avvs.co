title: Масштабируем Elasticsearch
subtitle: оптимизация реального кластера с индексами в несколько терабайт
date: 2014-05-26
author: Виталий Аминев
gravatarMail: v@aminev.me
tags: [Elasticsearch]
---

## Медленные запросы в Elaticsearch

Итак, работая над поисковым движком по социальной информации мы остановили свой выбор на Elasticsearch, так как по отзывам он был очень легок в настройке и использование, имел огромные поисковые возможности и в целом выглядел как манна небесная. Все в целом так и было до тех пор пока наш индекс не вырос до более-менее приличных миллиарда (1 млрд) документов.

Даже банальный `Term query` мог занять десятки (!) секунд. Документации по ES не так много, как хотелось бы, а гуглинг данного вопроса выдавал результаты 2х-летней давности по совсем не актуальным версиям нашего поискового движка (мы работаем с 0.90.13 - что тоже не самый айс, но мы не можем позволить себе опустить весь кластер, обновить его, и запустить заново на текущий момент - только роллинг рестарты).

## Низкая скорость индексации Elasticsearch

Вторая проблема - мы индексируем больше документов в секунду, чем Elasticsearch может обрабатывать. Тайм-ауты, огромная нагрузка на Write IO, очереди из процессов по 400 единиц. Все выглядит очень страшно, когда смотришь на это в Marvel.

## Как масштабировать кластер Elasticsearch

Исходная ситуация:

* 5 data (!) nodes, http enabled:
  * 100 GB RAM
  * 16 cores
  * 4 TB HDD (7200 RPM, seagate)
* Индексы:
  * от 500 до 1 млрд документов, всего порядка 5 штук
  * количество primary шардов от 50 до 400 (здесь мы тестировали разные стратегии индексирования - эта настройка очень важна)
  * реплики - от 2 до 5
  * размер индекса до 1,5 терабайт
  
Проблема: медленные запросы, и, самое печальное, мы индексируем больше, чем позволяют наши машины
